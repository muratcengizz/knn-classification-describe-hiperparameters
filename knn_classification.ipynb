{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c4abe2-a354-4191-8aef-939a50bc8ebd",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor (KNN) Classification\n",
    "## Bana arkadaşını söyle sana kim olduğunu söyliyeyim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b03f1-bd0c-4347-8c6a-6e80648094bb",
   "metadata": {},
   "source": [
    "### K-en yakın komşular (k-NN) sınıflandırma algoritması, basit ama etkili bir makine öğrenimi algoritmasıdır. Temel fikir, bir veri noktasını sınıflandırmak için o noktanın en yakın komşularını kullanmaktır.\n",
    "\n",
    "## k-NN algoritmasının çalışma mantığı şu adımları içerir:\n",
    "### Veri Kümesi Hazırlığı: İlk adım, eğitim veri kümesinin hazırlanmasıdır. Bu adımda, sınıflandırma yapmak istediğiniz örnekler ve bunların etiketleri bulunur. Örneğin, bir fotoğraftaki nesneleri tanımak istiyorsanız, fotoğraflar ve bu fotoğraflardaki nesnelerin etiketleri kullanılır.\n",
    "\n",
    "### Ölçü Matrisi: K-NN algoritması, veri noktaları arasındaki benzerliği ölçmek için bir ölçü matrisi kullanır. Ölçü matrisi, genellikle Öklidyen mesafesi gibi bir mesafe ölçüsüdür. Öklidyen mesafesi, iki veri noktası arasındaki doğrusal uzaklığı hesaplar. Bunula birlikte, farklı ölçü matrisleri de kullanılabilir, örneğin Manhattan mesafesi.\n",
    "\n",
    "### Eğitim: Eğitim adımında, veri noktaları ve etiketleri kullanılarak k-NN modeli oluştururlur. Model, veri noktalarını belleğinde tutar ve sınıflandırma yapmak için bu noktaları kullanır.\n",
    "\n",
    "### Sınıflandırma: Sınıflandırma adımında, sınıflandırmak istediğiniz bir veri noktası verildiğinde, algoritma ölçü matrisini kullanarak bu noktanın k-en yakın komşusunu belirler. k, bir parametredir ve kullanıcının belirlemesi gereken bir değerdir. Daha sonra, k-en yakın komşuların etiketlerine bakarak sınıflandırma yapar. Örneğin, eğer k=3 olarak belirlenmişse ve üç en yakın komşu kırmızı, mavi ve yeşil etiketlere sahipse, algoritma yeni noktayı çoğunluğun etiketiyle sınıflandırır.\n",
    "\n",
    "### Performans Değerlendirmesi: Oluşturulan k-NN modelinin performansını değerlendirmek için test veri kümesi kullanılır. Test veri kümesindeki veri noktaları, modelin sınıflandırma performansını ölçmek için kullanılır. Bu adım, modelin doğruluğunu ve genel performansını değerlendirmek için önemlidir.\n",
    "\n",
    "### K-NN algoritması, basit ve anlaşılır olmasının yanı sıra, eğitim süreci nispeten hızlır. Bunula birlikte, büyük veri kümeleriyle çalışırken zaman ve bellek açısından yoğun olabilir. Ayrıca, veri noktalarının ölçeklenmesi ve uygun bir k değerinin seçilmesi gibi ön işleme adımları da dikkate alınmalıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fa54a3-b6cd-4776-b4c6-f3c3a9ab7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e215ad51-8102-4a9a-b950-55bd6d1cbd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bd47c-b7a5-4b7f-bf5a-22870dd88c5b",
   "metadata": {},
   "source": [
    "### n_neighbors: Bu hiperparametre, sınıflandırmada kullanılacak olan en yakın komşu sayısını belirler. Örneğin, n_neighbors=5 olarak belirlenirse, bir veri noktasının sınıflandırılması için en yakın 5 komşu kullanılır.\n",
    "\n",
    "### weights: Bu hiperparametre, k-en yakın komşuların ağırlıklarını belirler. İki yaygın seçenek vardır: 'uniform' ve 'distance'. 'uniform', tüm komşulara aynı ağırlığı verirken, 'distance', komşuların mesafelerine ters orantılı olarak ağırlık verir.\n",
    "\n",
    "### algorithm: Bu hiperparametre, k-en yakın komşuların bulunmasında kullanılacak olan algoritmayı belirler. 'auto' değeri, verilere bağlı olarak en uygun algoritmayı belirler. 'ball_tree', veri noktalarını bir küre ağacı yapısı kullanarak hızlı bir şekilde arar. 'kd_tree', veri noktalarını bir KD ağacı yapısı kullanarak arar. 'brute' ise brute-force yaklaşımını kullanır ve tüm veri noktalarını karşılaştırır. 'brute' algoritması genellikle küçük veri setleri için uygundur.\n",
    "\n",
    "### leaf_size: Bu hiperparametre, 'ball_tree' veya 'kd_tree' algoritması kullanılıyorsa, ağaçta yaprak düpğmlerinin maksimum boyutunu belirler. Daha büyük bir leaf_size, daha az bellek kullanımı ve daha yavaş hesaplamalar anlamına gelebilir.\n",
    "\n",
    "### p: Bu hiperparametre, kullanılacak mesafe metriğini belirler. p=1 ise Manhattan mesafesi kullanılırken, p=2 ise Öklidyen mesafesi kullanılır. Genellikle Öklidyen mesafesi (p=2) tercih edilen seçenektir.\n",
    "\n",
    "### Bu hiperparametrelerin genelde hangi değerleri aldığı veri setine ve kullanım durumuna bağlıdır. Örneğin, n_neighbors için genellikle 3-10 arası değerler tercih edilirken, weights için 'uniform' veya 'distance' seçilebilir. Diğer hiperparametreler ise genellikle varsayılan değerlerle iyi sonuçlar verir, ancak özelleştirilmesi gereken durumlar da olabilir. Önemli olan, hiperparametreleri deneyerek ve uygun değerleri belirleyerek modelin performansını iyileştirmektir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
